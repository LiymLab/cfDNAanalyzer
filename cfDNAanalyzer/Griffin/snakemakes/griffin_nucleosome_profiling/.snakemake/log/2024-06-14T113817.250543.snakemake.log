Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	calc_cov
	1	generate_plots
	1	merge_sites
	4

[Fri Jun 14 11:38:17 2024]
rule calc_cov:
    input: /home/zjp/projects/202312_cfDNA_integrated_tools/input/NCBI_pair/sorted_pair_bwa_hg38.bam, /home/zjp/projects/202312_cfDNA_integrated_tools/Griffin/snakemakes/griffin_GC_and_mappability_correction/results/GC_bias/sample_name_1.GC_bias.txt
    output: tmp/sample_name_1/tmp_bigWig/sample_name_1.uncorrected.bw, tmp/sample_name_1/tmp_bigWig/sample_name_1.GC_corrected.bw, tmp/sample_name_1/tmp_pybedtools
    jobid: 3
    wildcards: samples=sample_name_1

Removing temporary output file tmp/sample_name_1/tmp_pybedtools.
[Fri Jun 14 11:55:20 2024]
Finished job 3.
1 of 4 steps (25%) done

[Fri Jun 14 11:55:20 2024]
rule merge_sites:
    input: tmp/sample_name_1/tmp_bigWig/sample_name_1.uncorrected.bw, tmp/sample_name_1/tmp_bigWig/sample_name_1.GC_corrected.bw
    output: results/sample_name_1/sample_name_1.uncorrected.coverage.tsv, results/sample_name_1/sample_name_1.GC_corrected.coverage.tsv, tmp/sample_name_1/tmp_pybedtools2
    jobid: 1
    wildcards: samples=sample_name_1

[Fri Jun 14 12:01:11 2024]
Error in rule merge_sites:
    jobid: 1
    output: results/sample_name_1/sample_name_1.uncorrected.coverage.tsv, results/sample_name_1/sample_name_1.GC_corrected.coverage.tsv, tmp/sample_name_1/tmp_pybedtools2
    shell:
        time ../../scripts/griffin_merge_sites.py 		--sample_name sample_name_1 		--uncorrected_bw_path tmp/sample_name_1/tmp_bigWig/sample_name_1.uncorrected.bw 		--GC_corrected_bw_path tmp/sample_name_1/tmp_bigWig/sample_name_1.GC_corrected.bw 		--GC_map_corrected_bw_path none 		--mappability_correction False 		--tmp_dir tmp 		--results_dir results 		--mappability_bw ../../Ref/k100.Umap.MultiTrackMappability.bw 		--chrom_sizes_path ../../Ref/hg38.standard.chrom.sizes 		--sites_yaml config/sites.yaml 		--griffin_scripts ../../scripts 		--chrom_column Chrom 		--position_column position 		--strand_column Strand 		--chroms chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 		--norm_window -5000 5000 		--save_window -1000 1000 		--center_window -30 30 		--fft_window -1000 1000 		--fft_index 10 		--smoothing_length 165 		--exclude_paths ../../Ref/encode_unified_GRCh38_exclusion_list.bed ../../Ref/hg38_centromeres.bed ../../Ref/hg38_gaps.bed ../../Ref/hg38_fix_patches.bed ../../Ref/hg38_alternative_haplotypes.bed 		--step 15 		--CNA_normalization False 		--individual False 		--smoothing True 		--exclude_outliers True 		--exclude_zero_mappability True 		--number_of_sites none 		--sort_by none 		--ascending none 		--CPU 8 
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job merge_sites since they might be corrupted:
tmp/sample_name_1/tmp_pybedtools2
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/zjp/projects/202312_cfDNA_integrated_tools/Griffin/snakemakes/griffin_nucleosome_profiling/.snakemake/log/2024-06-14T113817.250543.snakemake.log
