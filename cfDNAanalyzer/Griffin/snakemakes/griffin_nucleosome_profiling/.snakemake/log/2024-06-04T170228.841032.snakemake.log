Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	generate_plots
	1	merge_sites
	3

[Tue Jun  4 17:02:28 2024]
rule merge_sites:
    input: tmp/sample_name_1/tmp_bigWig/sample_name_1.uncorrected.bw, tmp/sample_name_1/tmp_bigWig/sample_name_1.GC_corrected.bw
    output: results/sample_name_1/sample_name_1.uncorrected.coverage.tsv, results/sample_name_1/sample_name_1.GC_corrected.coverage.tsv, tmp/sample_name_1/tmp_pybedtools2
    jobid: 1
    wildcards: samples=sample_name_1

Removing temporary output file tmp/sample_name_1/tmp_bigWig/sample_name_1.GC_corrected.bw.
Removing temporary output file tmp/sample_name_1/tmp_bigWig/sample_name_1.uncorrected.bw.
Removing temporary output file tmp/sample_name_1/tmp_pybedtools2.
[Tue Jun  4 17:02:38 2024]
Finished job 1.
1 of 3 steps (33%) done

[Tue Jun  4 17:02:38 2024]
rule generate_plots:
    input: results/sample_name_1/sample_name_1.uncorrected.coverage.tsv, results/sample_name_1/sample_name_1.GC_corrected.coverage.tsv
    output: results/plots/site_name1.pdf
    jobid: 2

[Tue Jun  4 17:02:39 2024]
Finished job 2.
2 of 3 steps (67%) done

[Tue Jun  4 17:02:39 2024]
localrule all:
    input: results/sample_name_1/sample_name_1.GC_corrected.coverage.tsv, results/plots/site_name1.pdf
    jobid: 0

[Tue Jun  4 17:02:39 2024]
Finished job 0.
3 of 3 steps (100%) done
Complete log: /home/zjp/projects/202312_cfDNA_integrated_tools/Griffin/snakemakes/griffin_nucleosome_profiling/.snakemake/log/2024-06-04T170228.841032.snakemake.log
