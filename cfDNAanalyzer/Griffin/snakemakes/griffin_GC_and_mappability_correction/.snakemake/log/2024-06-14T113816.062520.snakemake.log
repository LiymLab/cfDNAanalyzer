Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	make_samples_yaml
	2

[Fri Jun 14 11:38:16 2024]
rule make_samples_yaml:
    input: results/GC_bias/sample_name_1.GC_bias.txt
    output: results/samples.GC.yaml
    jobid: 3
    wildcards: out_dir=results

[Fri Jun 14 11:38:16 2024]
Finished job 3.
1 of 2 steps (50%) done

[Fri Jun 14 11:38:16 2024]
localrule all:
    input: results/GC_counts/sample_name_1.GC_counts.txt, results/GC_bias/sample_name_1.GC_bias.txt, results/GC_plots/sample_name_1.GC_bias.summary.pdf, results/samples.GC.yaml
    jobid: 0

[Fri Jun 14 11:38:16 2024]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /home/zjp/projects/202312_cfDNA_integrated_tools/Griffin/snakemakes/griffin_GC_and_mappability_correction/.snakemake/log/2024-06-14T113816.062520.snakemake.log
